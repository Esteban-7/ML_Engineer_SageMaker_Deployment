{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39838a9e",
   "metadata": {},
   "source": [
    "First the sagemaker package is installed in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3230619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker==1.72.0\n",
      "  Downloading sagemaker-1.72.0.tar.gz (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: boto3>=1.14.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.17.99)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.15.2)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.5.3)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (0.1.5)\n",
      "Collecting smdebug-rulesconfig==0.1.4\n",
      "  Downloading smdebug_rulesconfig-0.1.4-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (20.9)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (1.20.99)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.99->boto3>=1.14.12->sagemaker==1.72.0) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.99->boto3>=1.14.12->sagemaker==1.72.0) (1.26.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker==1.72.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker==1.72.0) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=20.0->sagemaker==1.72.0) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker==1.72.0) (1.15.0)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-1.72.0-py2.py3-none-any.whl size=386358 sha256=6b2a26abd15047aeb63c9d8754941183a532bb8d7b86a2a4a0848fd662a79585\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c3/58/70/85faf4437568bfaa4c419937569ba1fe54d44c5db42406bbd7\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: smdebug-rulesconfig, sagemaker\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 1.0.1\n",
      "    Uninstalling smdebug-rulesconfig-1.0.1:\n",
      "      Successfully uninstalled smdebug-rulesconfig-1.0.1\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.45.0\n",
      "    Uninstalling sagemaker-2.45.0:\n",
      "      Successfully uninstalled sagemaker-2.45.0\n",
      "Successfully installed sagemaker-1.72.0 smdebug-rulesconfig-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker==1.72.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9f3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sagemakar package that was prevously installed is imported. \n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "#The current session information is saved so it can be accessed later. \n",
    "session = sagemaker.Session() # Store the current SageMaker session\n",
    "role = get_execution_role()\n",
    "prefix = 'crossSell-xgboost' # a prefix is set so later on a folder on s3 can carry said name\n",
    "\n",
    "test_location = session.upload_data(\"processed_data/test.csv\", key_prefix=prefix)\n",
    "val_location = session.upload_data(\"processed_data/validation.csv\", key_prefix=prefix)\n",
    "train_location = session.upload_data(\"processed_data/train.csv\", key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f8ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n"
     ]
    }
   ],
   "source": [
    "#the sagemaker image for the xgboost estimator is now imported to create the container in which \n",
    "#the algorithm will run\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d592db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "#The estimator is now set, the information about the sagemaker session, container, role, etc.\n",
    "#is passed as parameters.\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    train_instance_count=1,                  # How many compute instances\n",
    "                                    train_instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "#The hyperparameters for the estimator are set. It is important to know that these are the baseline parameters\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d956fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With the estimator created and the baseline hyperparameters set. \n",
    "#An hyperparameter tuner is created and the estimator is passed as parameter.\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:logloss', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 6, # The total number of models to train\n",
    "                                               max_parallel_jobs = 3, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6751eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "#the datasets that were uploaded to s3 to train the model are prepared to use as input for the algorithm\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25f3ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The fit method is called on the tuner so Sagemaker can start the training jobs and estimating the models\n",
    "#and their metrics. the train and validation datasets in S3 are passed as parameters\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e6d8992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................!\n"
     ]
    }
   ],
   "source": [
    "#Since the training jobs are running on sagemaker but it cannot be visualized, the wait method\n",
    "#is called so it is visible when the training is complete\n",
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a322b247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-26 16:19:29 Starting - Preparing the instances for training\n",
      "2021-06-26 16:19:29 Downloading - Downloading input data\n",
      "2021-06-26 16:19:29 Training - Training image download completed. Training in progress.\n",
      "2021-06-26 16:19:29 Uploading - Uploading generated training model\n",
      "2021-06-26 16:19:29 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:19:17:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:19:17:INFO] Setting up HPO optimized metric to be : logloss\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:19:17:INFO] File size need to be processed in the node: 23.44mb. Available memory size in the node: 8416.43mb\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:19:17:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:19:17] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[16:19:17] 99679x10 matrix with 996790 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:19:17:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:19:17] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[16:19:17] 24920x10 matrix with 249200 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[16:19:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.633204#011validation-logloss:0.633706\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-logloss' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-logloss hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[16:19:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.58988#011validation-logloss:0.590719\u001b[0m\n",
      "\u001b[34m[16:19:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.557017#011validation-logloss:0.558251\u001b[0m\n",
      "\u001b[34m[16:19:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.531589#011validation-logloss:0.532997\u001b[0m\n",
      "\u001b[34m[16:19:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.511587#011validation-logloss:0.513164\u001b[0m\n",
      "\u001b[34m[16:19:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.495611#011validation-logloss:0.497263\u001b[0m\n",
      "\u001b[34m[16:19:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.482658#011validation-logloss:0.484402\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.471634#011validation-logloss:0.473546\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.462393#011validation-logloss:0.46441\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.454958#011validation-logloss:0.457055\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.448533#011validation-logloss:0.450646\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.443351#011validation-logloss:0.445516\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.439008#011validation-logloss:0.441211\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.435273#011validation-logloss:0.437532\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.432221#011validation-logloss:0.434561\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.429697#011validation-logloss:0.432052\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.427507#011validation-logloss:0.42988\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.425622#011validation-logloss:0.428\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.424054#011validation-logloss:0.426458\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.422731#011validation-logloss:0.42512\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.421622#011validation-logloss:0.424033\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.420614#011validation-logloss:0.423045\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.419682#011validation-logloss:0.422135\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.418955#011validation-logloss:0.421406\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.418267#011validation-logloss:0.420748\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.417741#011validation-logloss:0.420217\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.41731#011validation-logloss:0.419781\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.416965#011validation-logloss:0.419409\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.416676#011validation-logloss:0.419134\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.416281#011validation-logloss:0.418778\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.416011#011validation-logloss:0.418532\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.415736#011validation-logloss:0.418281\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.415401#011validation-logloss:0.417965\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.41522#011validation-logloss:0.417793\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.415094#011validation-logloss:0.417698\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.414957#011validation-logloss:0.417579\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.414592#011validation-logloss:0.417134\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.414422#011validation-logloss:0.416996\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.41421#011validation-logloss:0.416864\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.414109#011validation-logloss:0.416787\u001b[0m\n",
      "\u001b[34m[16:19:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.413926#011validation-logloss:0.416595\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.413794#011validation-logloss:0.416477\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.413628#011validation-logloss:0.416344\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.413527#011validation-logloss:0.416268\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.413403#011validation-logloss:0.416177\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.413251#011validation-logloss:0.416071\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.413197#011validation-logloss:0.416043\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.413126#011validation-logloss:0.415973\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.413075#011validation-logloss:0.415956\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.412991#011validation-logloss:0.415858\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[50]#011train-logloss:0.412928#011validation-logloss:0.415837\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[51]#011train-logloss:0.412855#011validation-logloss:0.41582\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[52]#011train-logloss:0.412798#011validation-logloss:0.415847\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[53]#011train-logloss:0.412746#011validation-logloss:0.415844\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[54]#011train-logloss:0.412642#011validation-logloss:0.415832\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[55]#011train-logloss:0.412575#011validation-logloss:0.415796\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[56]#011train-logloss:0.412555#011validation-logloss:0.415762\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[57]#011train-logloss:0.412483#011validation-logloss:0.415671\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[58]#011train-logloss:0.412458#011validation-logloss:0.415679\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[59]#011train-logloss:0.412426#011validation-logloss:0.415636\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[60]#011train-logloss:0.412334#011validation-logloss:0.415556\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[61]#011train-logloss:0.412291#011validation-logloss:0.415543\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[62]#011train-logloss:0.412224#011validation-logloss:0.415512\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[63]#011train-logloss:0.412139#011validation-logloss:0.415413\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[64]#011train-logloss:0.412121#011validation-logloss:0.415381\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[65]#011train-logloss:0.412081#011validation-logloss:0.415422\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[66]#011train-logloss:0.412021#011validation-logloss:0.415374\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[67]#011train-logloss:0.411993#011validation-logloss:0.415374\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 10 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[68]#011train-logloss:0.411986#011validation-logloss:0.41538\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[69]#011train-logloss:0.411944#011validation-logloss:0.415349\u001b[0m\n",
      "\u001b[34m[16:19:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[70]#011train-logloss:0.411938#011validation-logloss:0.41535\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[71]#011train-logloss:0.411839#011validation-logloss:0.415261\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[72]#011train-logloss:0.411805#011validation-logloss:0.415265\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[73]#011train-logloss:0.411779#011validation-logloss:0.415252\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[74]#011train-logloss:0.411736#011validation-logloss:0.415232\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[75]#011train-logloss:0.411716#011validation-logloss:0.415244\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[76]#011train-logloss:0.411684#011validation-logloss:0.415225\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[77]#011train-logloss:0.411658#011validation-logloss:0.415216\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[78]#011train-logloss:0.411617#011validation-logloss:0.415203\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[79]#011train-logloss:0.411575#011validation-logloss:0.41522\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[80]#011train-logloss:0.411512#011validation-logloss:0.415187\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[81]#011train-logloss:0.411498#011validation-logloss:0.41519\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[82]#011train-logloss:0.411482#011validation-logloss:0.415182\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[83]#011train-logloss:0.411459#011validation-logloss:0.415196\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[84]#011train-logloss:0.411447#011validation-logloss:0.415219\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[85]#011train-logloss:0.411426#011validation-logloss:0.415208\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[86]#011train-logloss:0.411401#011validation-logloss:0.415212\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[87]#011train-logloss:0.411374#011validation-logloss:0.415221\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[88]#011train-logloss:0.411354#011validation-logloss:0.41525\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[89]#011train-logloss:0.411288#011validation-logloss:0.415265\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[90]#011train-logloss:0.411236#011validation-logloss:0.415298\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[91]#011train-logloss:0.411201#011validation-logloss:0.415314\u001b[0m\n",
      "\u001b[34m[16:19:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-logloss:0.411201#011validation-logloss:0.415311\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[82]#011train-logloss:0.411482#011validation-logloss:0.415182\n",
      "\u001b[0m\n",
      "Training seconds: 49\n",
      "Billable seconds: 49\n"
     ]
    }
   ],
   "source": [
    "#When the training jobs are completed, the best model is attached to a new estimator object\n",
    "\n",
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f38c69d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "#A transformer object is scpecified calling the transformer method on the newly  created estimator\n",
    "\n",
    "xgb_transformer = xgb_attached.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86c69de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the transformer object the predictions are calculated based on the test dataset previously created\n",
    "\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "676c4244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-06-26 16:26:22 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-06-26 16:26:22 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-26 16:26:22 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-06-26 16:26:22 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2021-06-26 16:26:22 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-06-26 16:26:22 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-06-26 16:26:22 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:26:22:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:26:22:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:26:22:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:26:22:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:26:27:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-06-26:16:26:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\n",
      "\u001b[32m2021-06-26T16:26:26.404:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Since the transform method is running on sagemaker and is not visible, the wait method is called again\n",
    "\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fbff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the directory in which it is wanted to save the predictions made by the transformer is saved as a varible\n",
    "\n",
    "data_dir = '../project/processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5eb2c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-2-730413480526/xgboost-210626-1612-004-a27e4f29-2021-06-26-16-21-38-571/test.csv.out to processed_data/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "#Using the string variable referencing the directory to save the predictions, these are copied from the \n",
    "#S3 bucket to the local directory\n",
    "\n",
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4829ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some additional imports are needed to read both the actual labels and the predictions saved\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c2c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The predictions are loaded using the pandas library. Since the predictions are floats\n",
    "#(values from 01 to 1), they are rounded.\n",
    "\n",
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "predictions = [round(num) for num in predictions.squeeze().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e2bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the labels for the test dataset are uploaded using pandas and are transformed into an array so they can be\n",
    "#compared against the predictions\n",
    "\n",
    "test_y = pd.read_csv(\"processed_data/test_y.csv\", header=None)\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ffda14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82      9230\n",
      "           1       0.62      0.78      0.70      4615\n",
      "\n",
      "    accuracy                           0.77     13845\n",
      "   macro avg       0.75      0.77      0.76     13845\n",
      "weighted avg       0.79      0.77      0.78     13845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The confusion matriz and classification report are imported from the sklearn package\n",
    "#Finally, the results of the model can be analyzed by a classification report. \n",
    "#The analysis for these results are present on the report document related to this notebook. \n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(\"Classification Report \\n\")\n",
    "print(classification_report(test_y,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
